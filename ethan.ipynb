{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import json\n",
    "\n",
    "# Utilities\n",
    "from PIL import Image\n",
    "import glob # Khoa's stuff\n",
    "from IPython import display\n",
    "from tqdm import tqdm # for training progress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "Change based on system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10 # Do not change unless testing\n",
    "BATCH_SIZE = 200 # Based on system \n",
    "DATASET_PATH = \"./dataset/\" # Based on system\n",
    "\n",
    "IMAGE_SHAPE = (64, 64, 3) # Should not change\n",
    "LATENT_DIM = 512 # Do not change unless testing, the smaller the better"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Done in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "x_train, x_test = image_dataset_from_directory(\n",
    "    DATASET_PATH, \n",
    "    labels=None, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    image_size=IMAGE_SHAPE[:-1], \n",
    "    shuffle=False, # Don't think this matters\n",
    "    validation_split=0.1, \n",
    "    subset=\"both\",\n",
    "    crop_to_aspect_ratio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dataset\n",
    "x_train = x_train.map(lambda x: x/255)\n",
    "x_test = x_test.map(lambda x: x/255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a few images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to investigate memory usage, but should be good\n",
    "train_iter, test_iter = x_train.as_numpy_iterator(), x_test.as_numpy_iterator()\n",
    "\n",
    "fig = plt.figure(figsize=(2, 2))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(next(train_iter)[0]) # First image of batch 0 of x_train\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(next(train_iter)[1]) # Second image of batch 1 of x_train for variety's sakes\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(next(test_iter)[0]) # First image of batch 0 of x_test\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(next(test_iter)[1]) # Second image of batch 1 of x_test for variety's sakes\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(64, 64, 3)),\n",
    "    # Fill in the rest of the model\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(LATENT_DIM, activation='sigmoid') # Number of features we're condensing down to\n",
    "], name=\"face_encoder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(LATENT_DIM)),\n",
    "    # Fill in the rest of the model\n",
    "    layers.Conv2DTranspose(3, (5, 5), strides=1, padding='same', use_bias=False, activation='relu'),\n",
    "    layers.BatchNormalization()\n",
    "], name=\"face_decoder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder Subclassing\n",
    "Allow for the use of the Keras model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "  def __init__(self, encoder_model, decoder_model):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder_model\n",
    "    self.decoder = decoder_model\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "  def train_step(self, data):\n",
    "    train_data = (data, data) # Im too lazy to customize dataset behaviour\n",
    "    return super().train_step(train_data)\n",
    "\n",
    "  def test_step(self, data):\n",
    "    test_data = (data, data) # Im too lazy to customize dataset behaviour\n",
    "    return super().test_step(test_data)\n",
    "\n",
    "autoencoder = Autoencoder(encoder, decoder)\n",
    "# Paper points: loss functions\n",
    "autoencoder.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_iterator = x_test.as_numpy_iterator()\n",
    "test_batch = next(x_test_iterator)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  plt.imshow(test_batch[i])\n",
    "  plt.title(\"original\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.imshow(decoded_imgs[i])\n",
    "  plt.title(\"decompressed\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa7df7e7e1a965c066ecfed6febd4efd2732dd28503afd01e6fd0b7c58c135ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
