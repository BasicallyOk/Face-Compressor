{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import json\n",
    "\n",
    "# Utilities\n",
    "from PIL import Image\n",
    "import glob # Khoa's stuff\n",
    "from IPython import display\n",
    "from tqdm import tqdm # for training progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "Change based on system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100 # Do not change unless testing\n",
    "BATCH_SIZE = 100 # Based on system \n",
    "DATASET_PATH = \"./dataset/\" # Based on system\n",
    "\n",
    "IMAGE_SHAPE = (64, 64, 3) # Should not change\n",
    "LATENT_DIM = 32 # Do not change unless testing, the smaller the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_and_show_images(original: np.ndarray, generated: np.ndarray, id: str, save: bool=True):\n",
    "    \"\"\"\n",
    "    Compare and show original vs generated images.\n",
    "    Only allow 2 images to be compared against 2 images.\n",
    "    Allow for a visual check of the model's progress.\n",
    "    Parameters:\n",
    "        - original: numpy array containing the original images (shape (4, 64, 64, 3))\n",
    "        - generated: numpy array containing the corresponding generated images (shape (4, 64, 64, 3))\n",
    "        - id: something to save using\n",
    "        - save: whether to save or not\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(2, 2))\n",
    "\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(generated[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, 2, i+3)\n",
    "        plt.imshow(original[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\"./generated_images/{}.png\".format(id))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Done in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "x_train, x_test = image_dataset_from_directory(DATASET_PATH, labels=None, batch_size=BATCH_SIZE, image_size=IMAGE_SHAPE[:-1], validation_split=0.1, subset=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a few images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2, 2))\n",
    "print(x_train[0][0])\n",
    "print(x_train[0][1])\n",
    "print(x_train[0][2])\n",
    "print(x_train[0][3])\n",
    "for i in range(4):\n",
    "  plt.subplot(2, 2, i+1)\n",
    "  plt.imshow(x_train[0][0][i])\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(64, 64, 3)),\n",
    "    # Fill in the rest of the model\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(LATENT_DIM, activation='sigmoid') # Number of features we're condensing down to\n",
    "], name=\"face_encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(LATENT_DIM)),\n",
    "    # Fill in the rest of the model\n",
    "    layers.Conv2DTranspose(3, (5, 5), strides=1, padding='same', use_bias=False, activation='relu'),\n",
    "    layers.BatchNormalization()\n",
    "], name=\"face_decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder Subclassing\n",
    "Allow for the use of the Keras model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "  def __init__(self, encoder_model, decoder_model):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder_model\n",
    "    self.decoder = decoder_model\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "  def train_step(self, data):\n",
    "    train_data = (data, data) # Im too lazy to customize dataset behaviour\n",
    "    return super().train_step(train_data)\n",
    "\n",
    "autoencoder = Autoencoder(encoder, decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_iterator = x_test.as_numpy_iterator()\n",
    "test_batch = next(x_test_iterator)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  plt.imshow(test_batch[i])\n",
    "  plt.title(\"original\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.imshow(decoded_imgs[i])\n",
    "  plt.title(\"reconstructed\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa7df7e7e1a965c066ecfed6febd4efd2732dd28503afd01e6fd0b7c58c135ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
